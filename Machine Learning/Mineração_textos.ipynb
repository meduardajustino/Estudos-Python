{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbGClnOP1/q0GG+WssU8i2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Mineração de Textos (Text Mining)\n","- Obter informações a partir de um texto utilizando o Processamento de Linguagem Natural (NLP) que converte a linguagem humana para um formato que o computador possa ler.\n","\n","- Logo, obtemos padrões de textos que podem ser usados para análises, buscar informações, extrair, traduzir, sumarizar.\n","\n","- No Python, usaremos a bib NLTK - Natural Language Toolkit, que contém algoritmos para análise de sentimentos, extração de tópicos. Outra biblioteca que também será usada é ainda a sklearn que contém algoritmos de pré-processamento para TF-IDF e Bag of Words, entre outros."],"metadata":{"id":"Bw-JI5qVCn90"}},{"cell_type":"markdown","source":["### Expressões regulares (regex)\n","\n","- manipulações como encontrar palavras em docs, remover caracteres"],"metadata":{"id":"vDhbVKgFENjJ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYeJk5DiCWRE","executionInfo":{"status":"ok","timestamp":1730990715775,"user_tz":180,"elapsed":434,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"fb7849dd-5d8e-46e6-9d07-aaf8b89e852b"},"outputs":[{"output_type":"stream","name":"stdout","text":["<re.Match object; span=(0, 2), match='ab'>\n","None\n"]}],"source":["# Importa a biblioteca de expressão regular ou regular expression (re)\n","import re\n","\n","# Encontra a palavra ab no texto abcdef\n","print(re.match('ab', 'abcde'))\n","\n","# Procura pela palavra zz no texto abcde mas nao encontra nada\n","print(re.match('zz', 'abcde'))"]},{"cell_type":"markdown","source":["### Quais são os métodos mais comuns?\n","\n","re.match(): encontra equivalência se ela ocorrer no início da string. Uso: re.match(padrão, string)\n","\n","re.search(): similar a match() mas não nos restringe a encontrar equivalência apenas no começo da string. O método search() consegue encontrar um padrão em qualquer posição da string mas que **somente retorna a primeira ocorrência do padrão de busca**. Uso: re.search(padrão, string)\n","\n","re.findall(): obter uma lista de todos os padrões encontrados. Não há restrições em buscar do começo ou do fim. Funciona como ambas re.search() e re.match(). Uso: re.findall(padrão, string)\n","\n","re.split(): dividir a string pela ocorrências do padrão dado. Uso: re.split(padrão, string)\n","\n","re.sub(): Às vezes é útil buscar um padrão de string e substituí-lo por uma nova sub-string. Se o padrão não for encontrado, a string é retornada sem mudanças. Uso: re.sub(padrão, replace, string)"],"metadata":{"id":"XIZoeoAWEjZJ"}},{"cell_type":"markdown","source":["### Operadores mais comuns usados para especificar os padrões"],"metadata":{"id":"_UPMARTuGRHb"}},{"cell_type":"code","source":["# Extrair cada palavra usando “*”\n","print(re.findall('\\w*','IPEA - Instituto de Pesquisa Economica Aplicada'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2AUlLgFGsm6","executionInfo":{"status":"ok","timestamp":1730991040224,"user_tz":180,"elapsed":436,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"78009334-f3ae-4ec5-cfb6-abedfc649608"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['IPEA', '', '', '', 'Instituto', '', 'de', '', 'Pesquisa', '', 'Economica', '', 'Aplicada', '']\n"]}]},{"cell_type":"code","source":["# Extrair cada palavra usando “*”. Agora vamos remover os espaços com “+”.\n","print(re.findall(r'\\w+','IPEA - Instituto de Pesquisa Economica Aplicada'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDXBcjw9G010","executionInfo":{"status":"ok","timestamp":1730991070149,"user_tz":180,"elapsed":461,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"21dccc97-4309-49d4-94e4-ded719f4ba5d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['IPEA', 'Instituto', 'de', 'Pesquisa', 'Economica', 'Aplicada']\n"]}]},{"cell_type":"code","source":["print(re.findall('\\w+','IPEA Instituto'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaEzdlsyG064","executionInfo":{"status":"ok","timestamp":1730991109240,"user_tz":180,"elapsed":405,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"b6ff00de-54b6-468e-e845-780fe6b2c321"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['IPEA', 'Instituto']\n"]}]},{"cell_type":"code","source":["# Extrai a última palavra\n","print(re.findall(r'\\w+$','IPEA - Instituto de Pesquisa Economica Aplicada'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jccxOAGTG0-V","executionInfo":{"status":"ok","timestamp":1730991126166,"user_tz":180,"elapsed":493,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"f3c6d517-0732-4b20-f84f-4fc4073ec5ab"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['Aplicada']\n"]}]},{"cell_type":"code","source":["# Extrai a data de uma string. Usamos o \\d para extrair os dígitos.\n","result=re.findall(r'\\d{2}-\\d{2}-\\d{4}','Amit 34-3456 12-05-2007, XYZ 56-4532 11-11-2011, ABC 67-8945 12-01-2009')\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THU3iERbG1Bv","executionInfo":{"status":"ok","timestamp":1730991257861,"user_tz":180,"elapsed":514,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"1ae4f064-ffff-49c0-d9d3-54937f5d7797"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['12-05-2007', '11-11-2011', '12-01-2009']\n"]}]},{"cell_type":"code","source":["# Insere uma nova linha a cada . ? ou !\n","texto = 'IPEA. Instituto de Pesquisa Aplicada! Brasília-DF.'\n","re.split(\"[.]\", texto)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m3JJQ_xBHnxw","executionInfo":{"status":"ok","timestamp":1730991284923,"user_tz":180,"elapsed":432,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"e51a4856-8212-4fcb-ccbd-6400d388c124"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['IPEA', ' Instituto de Pesquisa Aplicada! Brasília-DF', '']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 1. Crie um texto com o seguinte conteúdo: \"A explosão aconteceu em 2005, porém só em 2012 foram desvendadas as causas do acidente.\"\n","texto = 'A explosão aconteceu em 2005, porém só em 2012 foram desvendadas as causas do acidente.'\n","# 2. Encontre e imprima apenas os números do texto criado para capturarmos os anos citados no texto.\n","print(re.findall('\\d+',texto))\n","# 3. Substitua todas as vírgulas por . e atribua a variavel de nome igual a texto2. Imprima texto2\n","texto2 = re.sub(',','.',texto)\n","# 4. Divida o texto2 onde tiver . e imprima o resultado\n","print(re.split('\\.',texto2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UGQa59ZIHn1z","executionInfo":{"status":"ok","timestamp":1730991512300,"user_tz":180,"elapsed":429,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"ff2d3de2-01fb-40b8-cf54-c05c8e519cb6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['2005', '2012']\n","['A explosão aconteceu em 2005', ' porém só em 2012 foram desvendadas as causas do acidente', '']\n"]}]},{"cell_type":"markdown","source":["### Pré-Processamento de Dados aplicado à textos\n","\n","Algumas técnicas aplicadas no pré-processamento com o foco em limpeza transformação, padronização do texto antes de minerar.\n","\n","- Transformação de letras para maiúsculas/minúsculas\n","- Tokenização\n","- Remoção de números, caracteres especiais e pontuação\n","- Remoção de Stopwords\n","- Stemming\n","- Lemmatization"],"metadata":{"id":"7JePNcOrIy_p"}},{"cell_type":"code","source":["dicionario = '''Significado de Economia\n","substantivo feminino\n","Ciência que analisa e estuda os mecanismos referentes à obtenção, à produção, ao consumo e à utilização dos bens materiais necessários à sobrevivência e ao bem-estar.\n","Poupança; contenção ou diminuição das despesas e dos gastos.\n","Organização de uma casa financeira e materialmente: economia doméstica.\n","[Figurado] Moderação no consumo; controle de excessos: economia de forças.\n","Organização; maneira através da qual vários elementos se organizam num todo.\n","Reunião das disciplinas que se baseiam nessa ciência; designação do curso superior que forma economistas.'''\n","\n","dicionario"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"QIgX5lOFJZUs","executionInfo":{"status":"ok","timestamp":1730992253237,"user_tz":180,"elapsed":556,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"156d209f-57df-4584-e580-9ca5acc9c4e4"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Significado de Economia\\nsubstantivo feminino\\nCiência que analisa e estuda os mecanismos referentes à obtenção, à produção, ao consumo e à utilização dos bens materiais necessários à sobrevivência e ao bem-estar.\\nPoupança; contenção ou diminuição das despesas e dos gastos.\\nOrganização de uma casa financeira e materialmente: economia doméstica.\\n[Figurado] Moderação no consumo; controle de excessos: economia de forças.\\nOrganização; maneira através da qual vários elementos se organizam num todo.\\nReunião das disciplinas que se baseiam nessa ciência; designação do curso superior que forma economistas.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Transformação de letras para minusculas\n","dicionario = dicionario.lower()"],"metadata":{"id":"q4WYZE9ZJY-_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tokenization - usada para extrair os tokens de um texto, como palavras e setenças de um texto. Mas também, pode extrair trechos de texto a partir de regras definidas em regex.\n","\n","- word_tokenize: faz a tokenização do texto em palavras\n","- sent_tokenize: faz em sentenças\n","- regexp_tokenize: faz de acordo com o padrão da expressão regular"],"metadata":{"id":"XN0xkLwBLqU0"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","\n","frase = \"Um frase muda o fim do filme. Mas é interno o maior labirinto. \"\n","\n","from nltk.tokenize import word_tokenize\n","word_tokenize(frase)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"im2R2A6uLp4C","executionInfo":{"status":"ok","timestamp":1730992731559,"user_tz":180,"elapsed":561,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"fa004142-beca-4506-aeb1-a00bb0127c75"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["['Um',\n"," 'frase',\n"," 'muda',\n"," 'o',\n"," 'fim',\n"," 'do',\n"," 'filme',\n"," '.',\n"," 'Mas',\n"," 'é',\n"," 'interno',\n"," 'o',\n"," 'maior',\n"," 'labirinto',\n"," '.']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# sequência de tokens únicos\n","tokens = set(word_tokenize(frase))\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5SQgjXsJatF","executionInfo":{"status":"ok","timestamp":1730992769297,"user_tz":180,"elapsed":422,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"1d355192-571f-427d-d71e-4ac91b88593c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.',\n"," 'Mas',\n"," 'Um',\n"," 'do',\n"," 'filme',\n"," 'fim',\n"," 'frase',\n"," 'interno',\n"," 'labirinto',\n"," 'maior',\n"," 'muda',\n"," 'o',\n"," 'é'}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# tokenização de sentenças\n","from nltk.tokenize import sent_tokenize\n","frases = sent_tokenize(frase)\n","frases"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RkCb0c9Jao5","executionInfo":{"status":"ok","timestamp":1730992825574,"user_tz":180,"elapsed":14,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"e7081c7c-7d16-4caf-b66b-47b36470fc62"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Um frase muda o fim do filme.', 'Mas é interno o maior labirinto.']"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize, sent_tokenize\n","dicp = word_tokenize(dicionario)\n","dics = sent_tokenize(dicionario)"],"metadata":{"id":"9DyRcDh0Q55h","executionInfo":{"status":"ok","timestamp":1730993695635,"user_tz":180,"elapsed":402,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import regexp_tokenize\n","regexp_tokenize(frase, '\\w+')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcoGAgkEJalK","executionInfo":{"status":"ok","timestamp":1730992845703,"user_tz":180,"elapsed":430,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"0d9fc75d-9846-4038-851c-07e5caf004f6"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Um',\n"," 'frase',\n"," 'muda',\n"," 'o',\n"," 'fim',\n"," 'do',\n"," 'filme',\n"," 'Mas',\n"," 'é',\n"," 'interno',\n"," 'o',\n"," 'maior',\n"," 'labirinto']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Remove a pontuação. Padrão: tudo que é diferente de palavras \\w e espaços \\s substitui por nda\n","import re\n","frase_limpa = re.sub(r'[^\\w\\s]','', frase) # para uma sentença\n","frase_limpa.capitalize()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OPHBIXThJagy","executionInfo":{"status":"ok","timestamp":1730992924497,"user_tz":180,"elapsed":23,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"7730ac5c-b07c-4e2c-9aa5-541bc23e3c19"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Um frase muda o fim do filme mas é interno o maior labirinto '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Remove caracteres especiais, pontuação e dígitos para uma lista\n","texto = [re.sub(\"(\\\\d|\\\\W)+\", \" \", e) for e in frases]\n","texto"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVhKewC3OFV_","executionInfo":{"status":"ok","timestamp":1730992957057,"user_tz":180,"elapsed":416,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"d1efc92d-d9d2-41cd-cf75-e7cfbacd3e2d"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Um frase muda o fim do filme ', 'Mas é interno o maior labirinto ']"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["Stopwords - palavras vazias ou muito frequentes que não agregam na análise. Elas são removidas para simplificar a análise do texto."],"metadata":{"id":"ZjONCeYFOBTp"}},{"cell_type":"code","source":["stopwords = ['objeto','contratação']"],"metadata":{"id":"j9L907Y8OFAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download das stopwords. OBS: lembre de habilitr o uso da Internet em Settings.\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","# Define as stopwords\n","stopwords = stopwords.words('portuguese')\n","\n","# Qtd de stopwords\n","print(len(stopwords))\n","\n","# Exemplo de stopwords\n","stopwords[0:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHjjDXojOcpx","executionInfo":{"status":"ok","timestamp":1730993065338,"user_tz":180,"elapsed":876,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"a8564ef3-8951-4790-e8a5-10c778d86d4b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["207\n"]},{"output_type":"execute_result","data":{"text/plain":["['a',\n"," 'à',\n"," 'ao',\n"," 'aos',\n"," 'aquela',\n"," 'aquelas',\n"," 'aquele',\n"," 'aqueles',\n"," 'aquilo',\n"," 'as']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Stemming diminui para o radical da palavra.\n","\n","Lemmatization diminui, porém é mais conservador e mantém o sentido da palavra."],"metadata":{"id":"21qm0OIGOsiF"}},{"cell_type":"code","source":["# Stemming\n","from nltk.stem import PorterStemmer\n","st = PorterStemmer()\n","word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n","for word in word_list: print(st.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOL8uaGcOcYi","executionInfo":{"status":"ok","timestamp":1730993200115,"user_tz":180,"elapsed":444,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"60e332c5-7036-497a-c29d-b517467d1f0d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["friend\n","friendship\n","friend\n","friendship\n"]}]},{"cell_type":"code","source":["# Stemming\n","from nltk.stem import LancasterStemmer\n","lancaster=LancasterStemmer()\n","word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n","for word in word_list: print(lancaster.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CeppocZFPIsp","executionInfo":{"status":"ok","timestamp":1730993242707,"user_tz":180,"elapsed":493,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"ac165b43-c41f-40e5-bfa6-89e913657bd8"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["friend\n","friend\n","friend\n","friend\n"]}]},{"cell_type":"code","source":["# Stemming em Portugues\n","from nltk.stem.snowball import SnowballStemmer\n","stemmer = SnowballStemmer(\"portuguese\")\n","for sentence in frase: print(stemmer.stem(sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IySBJlQhPInE","executionInfo":{"status":"ok","timestamp":1730993297188,"user_tz":180,"elapsed":435,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"eaa409bc-1280-4047-83e1-b822170b12a6"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["u\n","m\n"," \n","f\n","r\n","a\n","s\n","e\n"," \n","m\n","u\n","d\n","a\n"," \n","o\n"," \n","f\n","i\n","m\n"," \n","d\n","o\n"," \n","f\n","i\n","l\n","m\n","e\n",".\n"," \n","m\n","a\n","s\n"," \n","é\n"," \n","i\n","n\n","t\n","e\n","r\n","n\n","o\n"," \n","o\n"," \n","m\n","a\n","i\n","o\n","r\n"," \n","l\n","a\n","b\n","i\n","r\n","i\n","n\n","t\n","o\n",".\n"," \n"]}]},{"cell_type":"code","source":["# Lemmatization\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","lem = WordNetLemmatizer()\n","sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n","sentence_words = nltk.word_tokenize(sentence)\n","for sentence in sentence_words: print(lem.lemmatize(sentence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agx18hgVPei0","executionInfo":{"status":"ok","timestamp":1730993386021,"user_tz":180,"elapsed":2506,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"68bc1a0d-b989-452a-aaae-78efdb5b21a4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["He\n","wa\n","running\n","and\n","eating\n","at\n","same\n","time\n",".\n","He\n","ha\n","bad\n","habit\n","of\n","swimming\n","after\n","playing\n","long\n","hour\n","in\n","the\n","Sun\n",".\n"]}]},{"cell_type":"markdown","source":["### Bag of Words\n","\n","Para encontrar os termos de um texto, iniciamos com o pré-processamento que envolve a limpeza. Depois, fazemos a tokenização. A partir da tokenização, criamos o vocabulário. Por fim, fazemos a vetorização que irá gerar uma matriz do vocabulário com a quantidade de vezes que cada termo aparece no corpus.\n","\n"," O bag of words (BOW) é uma técnica usada para identificar tópicos num texto com base na frequencia que eles aparecem. Antes de usar Bag of Words, é preciso usar a tokenização para extrair as palavras ou sentenças de interesse. Depois, contamos a quantidade de vezes que o token aparece. Quanto mais frequente a palavra, mais importante pode ser. É uma forma de encontrar as palavras mais significantes do texto.\n","\n","Limitações: A bag of words não considera o significado da palavra no documento, ignora o contexto em que é usado. Para documentos grandes, o tamanho do vetor pode ser enorme e resultar em muito tempo de processamento."],"metadata":{"id":"e_8RSCtHP5Lo"}},{"cell_type":"code","source":["# Contagem de tokens de palavra\n","from collections import Counter\n","contagempalavras = Counter(word_tokenize(frase))\n","contagempalavras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV47vJE2PkD3","executionInfo":{"status":"ok","timestamp":1730993529149,"user_tz":180,"elapsed":558,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"056d9a57-049f-4004-941e-b45d4489bdb2"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Um': 1,\n","         'frase': 1,\n","         'muda': 1,\n","         'o': 2,\n","         'fim': 1,\n","         'do': 1,\n","         'filme': 1,\n","         '.': 2,\n","         'Mas': 1,\n","         'é': 1,\n","         'interno': 1,\n","         'maior': 1,\n","         'labirinto': 1})"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Imprime as palavras mais comuns\n","print(contagempalavras.most_common(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnGCn0TxQPav","executionInfo":{"status":"ok","timestamp":1730993553000,"user_tz":180,"elapsed":404,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"49508609-fb9c-49e9-fdf8-bcf123a254f9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[('o', 2), ('.', 2), ('Um', 1), ('frase', 1), ('muda', 1), ('fim', 1), ('do', 1), ('filme', 1), ('Mas', 1), ('é', 1)]\n"]}]},{"cell_type":"code","source":["# Contagem de sentenças\n","from collections import Counter\n","contagemsentencas = Counter(sent_tokenize(frase))\n","contagemsentencas"],"metadata":{"id":"zKV01Z7OQTno"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bag of Words\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer()\n","\n","# Cria a matriz de baf of words\n","X = vectorizer.fit_transform(dics)\n","X.toarray()\n","\n","# Outra forma de imprimimr o mesmo resultado da matriz (X) de bag of words\n","print(vectorizer.fit_transform(dics).todense())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIikBltTQUbz","executionInfo":{"status":"ok","timestamp":1730993709208,"user_tz":180,"elapsed":420,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"12c028d3-1cc2-4a11-e257-397262be92b2"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1\n","  0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0]\n"," [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n","  1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"," [0 0 0 0 0 0 0 0 1 0 1 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0\n","  0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"," [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n","  0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1]\n"," [0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n","  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 1 1 0 0 0 1 0 0 0 0]]\n"]}]},{"cell_type":"code","source":["# Vocabulario.\n","print(vectorizer.vocabulary_)\n","\n","# Quantidade de palavras no vocabulário\n","len(vectorizer.vocabulary_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BB1k32QIRHvF","executionInfo":{"status":"ok","timestamp":1730993752554,"user_tz":180,"elapsed":463,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"4d70d988-c31a-4223-a3e9-f144faca1244"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["{'significado': 55, 'de': 14, 'economia': 22, 'substantivo': 57, 'feminino': 28, 'ciência': 7, 'que': 51, 'analisa': 0, 'estuda': 26, 'os': 46, 'mecanismos': 37, 'referentes': 52, 'obtenção': 43, 'produção': 49, 'ao': 1, 'consumo': 8, 'utilização': 61, 'dos': 21, 'bens': 5, 'materiais': 35, 'necessários': 39, 'sobrevivência': 56, 'bem': 4, 'estar': 25, 'poupança': 48, 'contenção': 9, 'ou': 47, 'diminuição': 17, 'das': 13, 'despesas': 16, 'gastos': 33, 'organização': 45, 'uma': 60, 'casa': 6, 'financeira': 30, 'materialmente': 36, 'doméstica': 20, 'figurado': 29, 'moderação': 38, 'no': 41, 'controle': 10, 'excessos': 27, 'forças': 32, 'maneira': 34, 'através': 2, 'da': 12, 'qual': 50, 'vários': 62, 'elementos': 24, 'se': 54, 'organizam': 44, 'num': 42, 'todo': 59, 'reunião': 53, 'disciplinas': 18, 'baseiam': 3, 'nessa': 40, 'designação': 15, 'do': 19, 'curso': 11, 'superior': 58, 'forma': 31, 'economistas': 23}\n"]},{"output_type":"execute_result","data":{"text/plain":["63"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# Atividade com fake news\n","\n","noticias = '''Funcionaria do Ibope e Datafolha denuncia manipulação das pesquisas eleitorais.\n","Pesquisa do Ipea traz informação errada sobre estupro e roupas curtas.\n","Datafolha está fazendo uma pesquisa eleitoral no Whatsapp.\n","Dilma tem contrato para Ibope manipular pesquisas.\n","Dilma gastou 73 milhões em um salão de beleza quando era presidente.\n","Uber vai comprar a Avianca e oferecer passagens com 50% de desconto.\n","Idosos têm direito a 50% de desconto em passagens aéreas.\n","Idoso ganhou viagem em jato da força aérea e foi ejetado sem querer.\n","Sérgio Moro anuncia fim do IPVA e diz que cobrança é ilegal.\n","Brasília terá parque da Disney.\n","'''\n","noticias = word_tokenize(noticias)\n","vectorizer = CountVectorizer()\n","vectorizer.fit_transform(noticias).todense()\n","len(vectorizer.vocabulary_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQRfA4wQRM0t","executionInfo":{"status":"ok","timestamp":1730993913271,"user_tz":180,"elapsed":488,"user":{"displayName":"Maria Eduarda Justino","userId":"01864282111967003839"}},"outputId":"adb9a732-f406-4c06-b094-64a1f4f82c8a"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["77"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# 1. Crie uma variavel com o texto de notícias falsas\n","# 2. Faça a tokenização das noticias\n","# 3. Crie o Bag of Words\n","# 4. Imprima o vocabulário\n","# 5. Qual a Quantidade de palavras no vocabulário?"],"metadata":{"id":"SmgX3a9TRxVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7tVLvOX2RxMZ"},"execution_count":null,"outputs":[]}]}